{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "メモリ強化新規デザイン3chanel_アイテム単体pool変更ipynb.ipynb ",
      "provenance": [],
      "collapsed_sections": [
        "UyrSIdKfbn6V",
        "jg5mpVkmAnpS",
        "m9nIDpZQAu0K",
        "QPblQfVyHaLf",
        "TgZcZhu5GHxd",
        "DhJAgd0FTr2d",
        "7Cjwy21ZT3ZV",
        "cyD0Ml9AT7ut",
        "Fhza6dAxPaOZ",
        "SeKdlNQcKLFb",
        "rdsOKU9Jai0b",
        "qLiroFvNarAd",
        "cxhGkUhLdRRJ",
        "TCDnNYDR5E2z",
        "2zc5n9Rd-EIk",
        "TyWy6e36DK5M",
        "65O2MQ2kDSf_"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXhRBpIHlTAW"
      },
      "source": [
        "#GPU使用時間と種類を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8BydTpdanEi"
      },
      "source": [
        "res = sp.Popen([\"cat\", \"/proc/uptime\"], stdout=sp.PIPE)\n",
        "    # 単位はHour\n",
        "use_time = float(sp.check_output([\"awk\", \"{print $1 /60 /60 }\"], stdin=res.stdout).decode().replace(\"\\n\",\"\"))\n",
        "print(use_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FISVOABV_HpC"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyrSIdKfbn6V"
      },
      "source": [
        "#ライブラリインポート\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJPhvzT0-Btt"
      },
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import time\n",
        "import subprocess as sp\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import math\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn.functional as F\n",
        "import imageio\n",
        "vgg19 = models.vgg19(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4Dpy1nkdKm5"
      },
      "source": [
        "#マウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYmiIYO883bl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg5mpVkmAnpS"
      },
      "source": [
        "#パラメータ定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krU0QNbaAN56"
      },
      "source": [
        "%cd drive/My\\ Drive\n",
        "#dataroot1=\"verygood_smis_left-shoes\"\n",
        "#dataroot2=\"new_smis_left-shoes_mask\"\n",
        "dataroot3=\"color_pants\"\n",
        "dataroot4=\"verygood_smis_pants_mask\"\n",
        "#dataroot5=\"new_smis_right-shoes\"\n",
        "#dataroot6=\"new_smis_right-shoes_mask\"\n",
        "dataroot7=\"color_skirt\"\n",
        "dataroot8=\"verygood_smis_skirt_mask\"\n",
        "dataroot9=\"color_tops\"\n",
        "dataroot10=\"verygood_smis_tops_mask\"\n",
        "dataroot11=\"color_persons\"\n",
        "num_thread=0\n",
        "batch_size=16\n",
        "num_epoch=15\n",
        "img_size=(128,96)\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "ngpu=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie8e3D3G7w9D"
      },
      "source": [
        "res = sp.Popen([\"cat\", \"/proc/uptime\"], stdout=sp.PIPE)\n",
        "    # 単位はHour\n",
        "use_time = float(sp.check_output([\"awk\", \"{print $1 /60 /60 }\"], stdin=res.stdout).decode().replace(\"\\n\",\"\"))\n",
        "print(use_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9nIDpZQAu0K"
      },
      "source": [
        "#データのロード\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaXy26DcAT5L"
      },
      "source": [
        "pants_dataset=dset.ImageFolder(root=dataroot3,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "pants_mask_dataset=dset.ImageFolder(root=dataroot4,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "skirt_dataset=dset.ImageFolder(root=dataroot7,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "skirt_mask_dataset=dset.ImageFolder(root=dataroot8,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "tops_dataset=dset.ImageFolder(root=dataroot9,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "tops_mask_dataset=dset.ImageFolder(root=dataroot10,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "person_dataset=dset.ImageFolder(root=dataroot11,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "pants_dataloader=torch.utils.data.DataLoader(pants_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)    \n",
        "pants_mask_dataloader=torch.utils.data.DataLoader(pants_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "skirt_dataloader=torch.utils.data.DataLoader(skirt_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "skirt_mask_dataloader=torch.utils.data.DataLoader(skirt_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "tops_dataloader=torch.utils.data.DataLoader(tops_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "tops_mask_dataloader=torch.utils.data.DataLoader(tops_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "person_dataloader=torch.utils.data.DataLoader(person_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "\n",
        "\n",
        "device=torch.device(\"cuda:0\")\n",
        "print(len(person_dataset))\n",
        "print(len(tops_dataset))\n",
        "print(len(tops_mask_dataset))\n",
        "print(len(skirt_dataset))\n",
        "print(len(skirt_mask_dataset))\n",
        "print(len(pants_dataset))\n",
        "print(len(pants_mask_dataset))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fu-w290G2fv"
      },
      "source": [
        "device=torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPblQfVyHaLf"
      },
      "source": [
        "#関数定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKd7NWztUINU"
      },
      "source": [
        "##切り抜き"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fX6wAW0HYZW"
      },
      "source": [
        "def overlay(p,f,tops,pants,skirt):\n",
        "  Mask=(tops+pants+skirt)\n",
        "  Mask=MaskTrans(Mask)\n",
        "  #print(Mask.size())\n",
        "  #print(p.size())\n",
        "  reverse=1-Mask\n",
        "  cutout1=p*reverse\n",
        "  #print(f[0][0][113][50],Mask[0][0][113][50])\n",
        "  cutout2=Mask*f\n",
        "  #print(cutout2[0][0][113][50])\n",
        "  out=cutout1+cutout2\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjfpc9NNUMdR"
      },
      "source": [
        "##mask閾値"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fosipO__eToJ"
      },
      "source": [
        "def  MaskTrans(mask):\n",
        "  for i in range(mask.size(0)):\n",
        "    for j in range(mask.size(1)):\n",
        "      for k in range(mask.size(2)):\n",
        "        for l in range(mask.size(3)):\n",
        "          if mask[i][j][k][l]>0.6:\n",
        "            mask[i][j][k][l]=1\n",
        "          else:\n",
        "            mask[i][j][k][l]=0\n",
        "  \n",
        "  return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uqbqrl-USsq"
      },
      "source": [
        "##重みの初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC9OpGtJOkg7"
      },
      "source": [
        "def init_weights(model):\n",
        "  if isinstance(model.modules,nn.Conv2d):\n",
        "      model.modules().weight.data.nomal_(0,0.002)\n",
        "      model.modules().bias.data.zero_()\n",
        "  if isinstance(model.modules,nn.ConvTranspose2d):\n",
        "      model.modules().weight.data.nomal_(0,0.002)\n",
        "      model.modules().bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl7Qbmsri0Gm"
      },
      "source": [
        "##KLDloss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29T88BldFUMg"
      },
      "source": [
        "def KLDloss(mu, logvar):\n",
        "  lamda=0.05\n",
        "  return lamda*(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fencgo_Mi3f8"
      },
      "source": [
        "##Featloss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D63SiYoMi6i_"
      },
      "source": [
        "def Featloss(t,f):\n",
        "  L1=nn.L1Loss()\n",
        "  lamda=10\n",
        "  size=len(t)\n",
        "  featloss = torch.full((1,), fill_value=0,dtype=torch.float32,device=device)\n",
        "\n",
        "  for i in range(size):\n",
        "    loss=L1(t[i].detach(),f[i])\n",
        "    featloss+=(lamda*loss)\n",
        "\n",
        "  return featloss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgZcZhu5GHxd"
      },
      "source": [
        "#クラス定義\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhJAgd0FTr2d"
      },
      "source": [
        "##Encoder-Decoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWqoZBW-GMTS"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  def __init__(self,ngpu):\n",
        "    super(EncoderDecoder,self).__init__()\n",
        "    self.ngpu=ngpu\n",
        "    #Encoder\n",
        "    df=3#class\n",
        "    self.down1_1=nn.Conv2d(3*df,32*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_1=nn.InstanceNorm2d(32*df,eps=1e-5)\n",
        "\n",
        "    self.Leaky=nn.LeakyReLU(0.2,inplace=True)\n",
        "    self.down1_2=nn.Conv2d(32*df,64*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_2=nn.InstanceNorm2d(64*df,eps=1e-5)\n",
        "\n",
        "    self.down1_3=nn.Conv2d(64*df,128*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_3=nn.InstanceNorm2d(128*df,eps=1e-5)\n",
        "\n",
        "    self.down1_4=nn.Conv2d(128*df,256*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_4=nn.InstanceNorm2d(256*df,eps=1e-5)\n",
        "\n",
        "    self.gamma=nn.Conv2d(256*df,8*df,3,2,1,bias=False)\n",
        "    self.beta=nn.Conv2d(256*df,8*df,3,2,1,bias=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #Decoder\n",
        "    self.down1_0=nn.Conv2d(8*df,320*df,3,1,1,groups=3)\n",
        "    \n",
        "    #1block\n",
        "    self.batch1_1=nn.BatchNorm2d(320*df,eps=1e-5)\n",
        "    self.pool1_1=nn.MaxPool2d(32)\n",
        "    self.share1_1=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.gamma1_1=nn.Conv2d(16*df,320*df,3,1,1,groups=3)\n",
        "    self.beta1_1=nn.Conv2d(16*df,320*df,3,1,1,groups=3)\n",
        "    self.leaky=nn.LeakyReLU(0.2)\n",
        "    self.gconv1_1=nn.Conv2d(320*df,320*df,3,1,1,groups=3)\n",
        "\n",
        "    self.batch1_2=nn.BatchNorm2d(320*df,eps=1e-5)\n",
        "    self.pool1_2=nn.MaxPool2d(32)\n",
        "    self.share1_2=nn.Conv2d(df*1,16*df,3,1,1,groups=3)\n",
        "    self.gamma1_2=nn.Conv2d(16*df,320*df,3,1,1,groups=3)\n",
        "    self.beta1_2=nn.Conv2d(16*df,320*df,3,1,1,groups=3)\n",
        "    self.gconv1_2=nn.Conv2d(320*df,320*df,3,1,1,groups=3)\n",
        "    self.unpool1_2=nn.Upsample(scale_factor=2,mode=\"nearest\")\n",
        "\n",
        "\n",
        "    #2block\n",
        "    self.batch2_1=nn.BatchNorm2d(320*df,eps=1e-5)\n",
        "    self.pool2_1=nn.MaxPool2d(16)\n",
        "    self.share2_1=nn.Conv2d(df*1,16*df,3,1,1,groups=3)\n",
        "    self.gamma2_1=nn.Conv2d(16*df,320*df,3,1,1,groups=3)\n",
        "    self.beta2_1=nn.Conv2d(16*df,320*df,3,1,1,groups=3)\n",
        "    self.gconv2_1=nn.Conv2d(320*df,320*df,3,1,1,groups=3)\n",
        "\n",
        "    self.batch2_2=nn.BatchNorm2d(320*df)\n",
        "    self.pool2_2=nn.MaxPool2d(16)\n",
        "    self.share2_2=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma2_2=nn.Conv2d(16*df,320*df,3,1,1,groups=3)\n",
        "    self.beta2_2=nn.Conv2d(16*df,320*df,3,1,1,groups=3)\n",
        "    self.gconv2_2=nn.Conv2d(320*df,320*df,3,1,1,groups=3)\n",
        "    self.unpool2_2=nn.Upsample(scale_factor=2,mode=\"nearest\")\n",
        "\n",
        "\n",
        "    #3block\n",
        "    self.batch3_1=nn.BatchNorm2d(320*df,eps=1e-5)\n",
        "    self.pool3_1=nn.MaxPool2d(8)\n",
        "    self.share3_1=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma3_1=nn.Conv2d(16*df,320*df,3,1,1,groups=2)\n",
        "    self.beta3_1=nn.Conv2d(16*df,320*df,3,1,1,groups=2)\n",
        "    self.gconv3_1=nn.Conv2d(320*df,160*df,3,1,1,groups=2)\n",
        "\n",
        "    self.batch3_2=nn.BatchNorm2d(160*df,eps=1e-5)\n",
        "    self.pool3_2=nn.MaxPool2d(8)\n",
        "    self.share3_2=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma3_2=nn.Conv2d(16*df,160*df,3,1,1,groups=2)\n",
        "    self.beta3_2=nn.Conv2d(16*df,160*df,3,1,1,groups=2)\n",
        "    self.gconv3_2=nn.Conv2d(160*df,160*df,3,1,1,groups=2)\n",
        "    self.unpool3_2=nn.Upsample(scale_factor=2,mode=\"nearest\")\n",
        "    \n",
        "    self.batch3_3=nn.BatchNorm2d(320*df,eps=1e-5)\n",
        "    self.pool3_3=nn.MaxPool2d(8)\n",
        "    self.share3_3=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma3_3=nn.Conv2d(16*df,320*df,3,1,1,groups=2)\n",
        "    self.beta3_3=nn.Conv2d(16*df,320*df,3,1,1,groups=2)\n",
        "    self.gconv3_3=nn.Conv2d(320*df,160*df,3,1,1,groups=2)\n",
        "    #self.unpool3_3=nn.MaxUnpool2d(2)\n",
        "\n",
        "\n",
        "    #4block\n",
        "    self.batch4_1=nn.BatchNorm2d(160*df,eps=1e-5)\n",
        "    self.pool4_1=nn.MaxPool2d(4)\n",
        "    self.share4_1=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma4_1=nn.Conv2d(16*df,160*df,3,1,1,groups=2)\n",
        "    self.beta4_1=nn.Conv2d(16*df,160*df,3,1,1,groups=2)\n",
        "    self.gconv4_1=nn.Conv2d(160*df,80*df,3,1,1,groups=2)\n",
        "\n",
        "    self.batch4_2=nn.BatchNorm2d(80*df,eps=1e-5)\n",
        "    self.pool4_2=nn.MaxPool2d(4)\n",
        "    self.share4_2=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma4_2=nn.Conv2d(16*df,80*df,3,1,1,groups=2)\n",
        "    self.beta4_2=nn.Conv2d(16*df,80*df,3,1,1,groups=2)\n",
        "    self.gconv4_2=nn.Conv2d(80*df,80*df,3,1,1,groups=2)\n",
        "    self.unpool4_2=nn.Upsample(scale_factor=4,mode=\"nearest\")\n",
        "    \n",
        "    self.batch4_3=nn.BatchNorm2d(160*df,eps=1e-5)\n",
        "    self.pool4_3=nn.MaxPool2d(4)\n",
        "    self.share4_3=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma4_3=nn.Conv2d(16*df,160*df,3,1,1,groups=2)\n",
        "    self.beta4_3=nn.Conv2d(16*df,160*df,3,1,1,groups=2)\n",
        "    self.gconv4_3=nn.Conv2d(160*df,80*df,1,1,0,groups=2)\n",
        "    #self.unpool4_3=nn.MaxUnpool2d(2)\n",
        "\n",
        "    #5block\n",
        "    self.batch5_1=nn.BatchNorm2d(80*df,eps=1e-5)\n",
        "    self.pool5_1=nn.MaxPool2d(1)\n",
        "    self.share5_1=nn.Conv2d(1*df,16*df,3,1,1,groups=1)\n",
        "    self.gamma5_1=nn.Conv2d(16*df,80*df,3,1,1,groups=1)\n",
        "    self.beta5_1=nn.Conv2d(16*df,80*df,3,1,1,groups=1)\n",
        "    self.gconv5_1=nn.Conv2d(80*df,20*df,3,1,1,groups=1)\n",
        "\n",
        "    self.batch5_2=nn.BatchNorm2d(20*df,eps=1e-5)\n",
        "    self.pool5_2=nn.MaxPool2d(1)\n",
        "    self.share5_2=nn.Conv2d(1*df,16*df,3,1,1,groups=1)\n",
        "    self.gamma5_2=nn.Conv2d(16*df,20*df,3,1,1,groups=1)\n",
        "    self.beta5_2=nn.Conv2d(16*df,20*df,3,1,1,groups=1)\n",
        "    self.gconv5_2=nn.Conv2d(20*df,20*df,3,1,1,groups=1)\n",
        "    #self.unpool5_2=nn.MaxUnpool2d(2)\n",
        "    \n",
        "    self.batch5_3=nn.BatchNorm2d(80*df,eps=1e-5)\n",
        "    self.pool5_3=nn.MaxPool2d(1)\n",
        "    self.share5_3=nn.Conv2d(1*df,16*df,3,1,1,groups=1)\n",
        "    self.gamma5_3=nn.Conv2d(16*df,80*df,3,1,1,groups=1)\n",
        "    self.beta5_3=nn.Conv2d(16*df,80*df,3,1,1,groups=1)\n",
        "    self.gconv5_3=nn.Conv2d(80*df,20*df,1,1,0,groups=1)\n",
        "    #self.unpool5_3=nn.MaxUnpool2d(2)\n",
        "\n",
        "    #lastblock\n",
        "    self.lastconv=nn.Conv2d(20*df,3,3,1,1)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def Encoder(self,input): \n",
        "    down1_1=self.down1_1(input)\n",
        "    innorm1_1=self.innorm1_1(down1_1)\n",
        "    #print(innorm1_1.size())\n",
        "\n",
        "    leaky1_2=self.Leaky(innorm1_1)\n",
        "    down1_2=self.down1_2(leaky1_2)\n",
        "    innorm1_2=self.innorm1_2(down1_2)\n",
        "    #print(innorm1_2.size())\n",
        "\n",
        "    leaky1_3=self.Leaky(innorm1_2)\n",
        "    down1_3=self.down1_3(leaky1_3)\n",
        "    innorm1_3=self.innorm1_3(down1_3)\n",
        "    #print(innorm1_3.size())\n",
        "\n",
        "    leaky1_4=self.Leaky(innorm1_3)\n",
        "    #print(leaky1_4.size())\n",
        "    down1_4=self.down1_4(leaky1_4)\n",
        "    innorm1_4=self.innorm1_4(down1_4)\n",
        "    #print(innorm1_4.size())\n",
        "    \n",
        "    leaky1_5=self.Leaky(innorm1_4)\n",
        "    #print(leaky1_5.size())\n",
        "    gamma=self.gamma(leaky1_5)\n",
        "    beta=self.beta(leaky1_5)\n",
        "    #print(gamma.size(),beta.size())\n",
        "    #print(\"---\"*10)\n",
        "    return gamma,beta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def Decoder(self,z,seg): \n",
        "    down1_0=self.down1_0(z)\n",
        "    \n",
        "\n",
        "    #1block\n",
        "    batch1_1=self.batch1_1(down1_0)\n",
        "    share1_1=self.relu(self.share1_1(self.pool1_1(seg)))\n",
        "    gamma1_1=self.gamma1_1(share1_1)\n",
        "    beta1_1=self.beta1_1(share1_1)\n",
        "    temp1_1=(batch1_1*gamma1_1)+beta1_1\n",
        "    out1_1=self.gconv1_1(self.leaky(temp1_1))\n",
        "\n",
        "    batch1_2=self.batch1_2(out1_1)\n",
        "    share1_2=self.relu(self.share1_2(self.pool1_2(seg)))\n",
        "    gamma1_2=self.gamma1_2(share1_2)\n",
        "    beta1_2=self.beta1_2(share1_2)\n",
        "    temp1_2=(batch1_2*gamma1_2)+beta1_2\n",
        "    out1_2=self.unpool1_2(self.gconv1_2(self.leaky(temp1_2)))\n",
        "    #print(out1_2.size())\n",
        "\n",
        "\n",
        "    #2block\n",
        "    batch2_1=self.batch2_1(out1_2)\n",
        "    share2_1=self.relu(self.share2_1(self.pool2_1(seg)))\n",
        "    gamma2_1=self.gamma2_1(share2_1)\n",
        "    beta2_1=self.beta2_1(share2_1)\n",
        "    temp2_1=(batch2_1*gamma2_1)+beta2_1\n",
        "    out2_1=self.gconv2_1(self.leaky(temp2_1))\n",
        "\n",
        "    batch2_2=self.batch2_2(out2_1)\n",
        "    share2_2=self.relu(self.share2_2(self.pool2_2(seg)))\n",
        "    gamma2_2=self.gamma2_2(share2_2)\n",
        "    beta2_2=self.beta2_2(share2_2)\n",
        "    temp2_2=(batch2_2*gamma2_2)+beta2_2\n",
        "    out2_2=self.unpool2_2(self.gconv2_2(self.leaky(temp2_2)))\n",
        "    #print(out2_2.size())\n",
        "\n",
        "\n",
        "    #3block\n",
        "    batch3_1=self.batch3_1(out2_2)\n",
        "    share3_1=self.relu(self.share3_1(self.pool3_1(seg)))\n",
        "    gamma3_1=self.gamma3_1(share3_1)\n",
        "    beta3_1=self.beta3_1(share3_1)\n",
        "    temp3_1=(batch3_1*gamma3_1)+beta3_1\n",
        "    out3_1=self.gconv3_1(self.leaky(temp3_1))\n",
        "\n",
        "    batch3_2=self.batch3_2(out3_1)\n",
        "    share3_2=self.relu(self.share3_2(self.pool3_2(seg)))\n",
        "    gamma3_2=self.gamma3_2(share3_2)\n",
        "    beta3_2=self.beta3_2(share3_2)\n",
        "    temp3_2=(batch3_2*gamma3_2)+beta3_2\n",
        "    out3_2=self.gconv3_2(self.leaky(temp3_2))\n",
        "\n",
        "    batch3_3=self.batch3_3(out2_2)\n",
        "    share3_3=self.relu(self.share3_3(self.pool3_3(seg)))\n",
        "    gamma3_3=self.gamma3_3(share3_3)\n",
        "    beta3_3=self.beta3_3(share3_3)\n",
        "    temp3_3=(batch3_3*gamma3_3)+beta3_3\n",
        "    out3_3=self.gconv3_3(self.leaky(temp3_3))\n",
        "    out3=self.unpool3_2(out3_2+out3_3)\n",
        "    #print(out3.size())\n",
        "\n",
        "\n",
        "    #4block\n",
        "    batch4_1=self.batch4_1(out3)\n",
        "    share4_1=self.relu(self.share4_1(self.pool4_1(seg)))\n",
        "    gamma4_1=self.gamma4_1(share4_1)\n",
        "    beta4_1=self.beta4_1(share4_1)\n",
        "    temp4_1=(batch4_1*gamma4_1)+beta4_1\n",
        "    out4_1=self.gconv4_1(self.leaky(temp4_1))\n",
        "\n",
        "    batch4_2=self.batch4_2(out4_1)\n",
        "    share4_2=self.relu(self.share4_2(self.pool4_2(seg)))\n",
        "    gamma4_2=self.gamma4_2(share4_2)\n",
        "    beta4_2=self.beta4_2(share4_2)\n",
        "    temp4_2=(batch4_2*gamma4_2)+beta4_2\n",
        "    out4_2=self.gconv4_2(self.leaky(temp4_2))\n",
        "\n",
        "    batch4_3=self.batch4_3(out3)\n",
        "    share4_3=self.relu(self.share4_3(self.pool4_3(seg)))\n",
        "    gamma4_3=self.gamma4_3(share4_3)\n",
        "    beta4_3=self.beta4_3(share4_3)\n",
        "    temp4_3=(batch4_3*gamma4_3)+beta4_3\n",
        "    #print(temp4_3.size())\n",
        "    out4_3=self.gconv4_3(self.leaky(temp4_3))\n",
        "    #print(out4_2.size(),out4_3.size())\n",
        "    out4=self.unpool4_2(out4_2+out4_3)\n",
        "    #print(out4.size())\n",
        "\n",
        "    #5block\n",
        "    batch5_1=self.batch5_1(out4)\n",
        "    share5_1=self.relu(self.share5_1(self.pool5_1(seg)))\n",
        "    gamma5_1=self.gamma5_1(share5_1)\n",
        "    beta5_1=self.beta5_1(share5_1)\n",
        "    #print(gamma5_1.size(),batch5_1.size())\n",
        "    temp5_1=(batch5_1*gamma5_1)+beta5_1\n",
        "    out5_1=self.gconv5_1(self.leaky(temp5_1))\n",
        "\n",
        "    batch5_2=self.batch5_2(out5_1)\n",
        "    share5_2=self.relu(self.share5_2(self.pool5_2(seg)))\n",
        "    gamma5_2=self.gamma5_2(share5_2)\n",
        "    beta5_2=self.beta5_2(share5_2)\n",
        "    temp5_2=(batch5_2*gamma5_2)+beta5_2\n",
        "    out5_2=self.gconv5_2(self.leaky(temp5_2))\n",
        "\n",
        "    batch5_3=self.batch5_3(out4)\n",
        "    share5_3=self.relu(self.share5_3(self.pool5_3(seg)))\n",
        "    gamma5_3=self.gamma5_3(share5_3)\n",
        "    beta5_3=self.beta5_3(share5_3)\n",
        "    temp5_3=(batch5_3*gamma5_3)+beta5_3\n",
        "    out5_3=self.gconv5_3(self.leaky(temp5_3))\n",
        "    out5=self.sigmoid(self.lastconv(self.leaky(out5_2+out5_3)))\n",
        "\n",
        "    return out5\n",
        "\n",
        "\n",
        "  def reparameterize(self,mu, logvar):\n",
        "      std = torch.exp(0.5 * logvar) #分散共分散のlogvarを標準偏差stdに変換\n",
        "      #print(std.size())\n",
        "      eps = torch.randn_like(std)\n",
        "      #print(mu)\n",
        "      #print(eps.mul(std) + mu)\n",
        "      return eps.mul(std) + mu\n",
        "\n",
        "\n",
        "  def forward(self,input,seg,Z,test=False,pre=False,encodeonly=False):\n",
        "    if not test and not pre and not encodeonly:\n",
        "      mu,logvar=self.Encoder(input)\n",
        "      z=self.reparameterize(mu,logvar)\n",
        "      #print(input.size(),seg.size())\n",
        "      fake=self.Decoder(z,seg)\n",
        "      return fake,mu,logvar,z\n",
        "    \n",
        "    elif pre==True:\n",
        "      fake=self.Decoder(Z,seg)\n",
        "      return fake\n",
        "\n",
        "    elif encodeonly==True:\n",
        "      mu,logvar=self.Encoder(input)\n",
        "      z=self.reparameterize(mu,logvar)\n",
        "      return z\n",
        "\n",
        "    else:\n",
        "      z=torch.randn((seg.size(0),24,4,3)).to(device)\n",
        "      fake=self.Decoder(z,seg)\n",
        "      return fake,z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cjwy21ZT3ZV"
      },
      "source": [
        "##Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EQl2xjyA5A3"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,ngpu):    \n",
        "    super(Discriminator,self).__init__()\n",
        "    self.ngpu=ngpu\n",
        "    df=3\n",
        "    dc=df+3#class\n",
        "    #1block\n",
        "    self.pool=nn.AvgPool2d(2)\n",
        "    self.down1_1=nn.Conv2d(dc,8*dc,4,2,2)\n",
        "    self.leaky=nn.LeakyReLU(0.2)\n",
        "\n",
        "    #2block\n",
        "    self.down1_2=nn.Conv2d(8*dc,16*dc,4,2,2)\n",
        "    self.innorm1_2=nn.InstanceNorm2d(16*dc)\n",
        "\n",
        "    #3block\n",
        "    self.down1_3=nn.Conv2d(16*dc,32*dc,4,2,2)\n",
        "    self.innorm1_3=nn.InstanceNorm2d(32*dc)\n",
        "\n",
        "    #4block\n",
        "    self.down1_4=nn.Conv2d(32*dc,64*dc,4,1,2)\n",
        "    self.innorm1_4=nn.InstanceNorm2d(64*dc)\n",
        "\n",
        "    #5block\n",
        "    self.down1_5=nn.Conv2d(64*dc,1,4,1,2)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "  def Discriminator(self,image,seg): \n",
        "    #print(image.size(),seg.size())\n",
        "    featmap=[]\n",
        "    data=torch.cat([image,seg],dim=1)\n",
        "    \n",
        "    #1block\n",
        "    pool1_1=self.pool(data)\n",
        "    down1_1=self.down1_1(pool1_1)\n",
        "    leaky1_1=self.leaky(down1_1)\n",
        "    featmap.append(leaky1_1)\n",
        "    #print(leaky1_1.size())\n",
        "\n",
        "    #2block\n",
        "    down1_2=self.down1_2(leaky1_1)\n",
        "    innorm1_2=self.innorm1_2(down1_2)\n",
        "    leaky1_2=self.leaky(innorm1_2)\n",
        "    featmap.append(leaky1_2)\n",
        "    #print(leaky1_2.size())\n",
        "\n",
        "    #3block\n",
        "    down1_3=self.down1_3(leaky1_2)\n",
        "    innorm1_3=self.innorm1_3(down1_3)\n",
        "    leaky1_3=self.leaky(innorm1_3)\n",
        "    featmap.append(leaky1_3)\n",
        "    #print(leaky1_3.size())\n",
        "\n",
        "\n",
        "\n",
        "    #4block\n",
        "    down1_4=self.down1_4(leaky1_3)\n",
        "    innorm1_4=self.innorm1_4(down1_4)\n",
        "    leaky1_4=self.leaky(innorm1_4)\n",
        "    featmap.append(leaky1_4)\n",
        "    #print(leaky1_4.size())\n",
        "\n",
        "    down1_5=self.down1_5(leaky1_4)\n",
        "    #print(down1_5.size())\n",
        "    #print(\"---\"*10)\n",
        "\n",
        "    return self.sigmoid(down1_5),featmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyD0Ml9AT7ut"
      },
      "source": [
        "##知覚損失(/有)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXrTi7USTXXN"
      },
      "source": [
        "class Vgg19Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Vgg19Loss, self).__init__()\n",
        "        features1=list(vgg19.features)[:3]\n",
        "        features2=list(vgg19.features)[:8]\n",
        "        features3=list(vgg19.features)[:13]\n",
        "        features4=list(vgg19.features)[:22]\n",
        "        features5=list(vgg19.features)[:31]\n",
        "        self.features1=nn.ModuleList(features1).eval()\n",
        "        self.features2=nn.ModuleList(features2).eval()\n",
        "        self.features3=nn.ModuleList(features3).eval()\n",
        "        self.features4=nn.ModuleList(features4).eval()\n",
        "        self.features5=nn.ModuleList(features5).eval()\n",
        "\n",
        "    def forward(self,x,y):\n",
        "        t1=x\n",
        "        t2=y\n",
        "        loss1=nn.MSELoss()\n",
        "        loss2=nn.MSELoss()\n",
        "        loss3=nn.MSELoss()\n",
        "        loss4=nn.MSELoss()\n",
        "        loss5=nn.MSELoss()\n",
        "\n",
        "        for f in self.features1:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        #print(x,y)\n",
        "        f1loss=torch.sqrt(loss1(x,y)/(64*128*96))\n",
        "    \n",
        "        \n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features2:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "       # print(x.size(),y.size())\n",
        "        f2loss=torch.sqrt(loss2(x,y)/(128*64*48))\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features3:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "       # print(x.size(),y.size())\n",
        "        f3loss=torch.sqrt(loss3(x,y)/(256*32*24))\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features4:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        #print(x.size(),y.size())\n",
        "        f4loss=torch.sqrt(loss4(x,y)/(512*16*12))\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features5:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        #print(x.size(),y.size())\n",
        "        f5loss=torch.sqrt(loss5(x,y)/(512*8*6))\n",
        "        lamda=10\n",
        "        #print((f1loss+f2loss+f3loss+f4loss+f5loss))\n",
        "\n",
        "        #return (f1loss+f2loss+f3loss+f4loss+f5loss)*10\n",
        "        return (f1loss+f2loss+f3loss+f4loss+f5loss)*10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhza6dAxPaOZ"
      },
      "source": [
        "#Encoder-Decoder,Discriminatorの初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNJMxVvjVwdc"
      },
      "source": [
        "netG=EncoderDecoder(ngpu).to(device)\n",
        "netG.apply(init_weights)\n",
        "\n",
        "netD=Discriminator(ngpu).to(device)\n",
        "netD.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeKdlNQcKLFb"
      },
      "source": [
        "#Adam最適化＆損失関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaQpTK6hKI9z"
      },
      "source": [
        "L1=nn.L1Loss()\n",
        "Lper=Vgg19Loss().to(device)\n",
        "Ladv=nn.BCELoss()\n",
        "\n",
        "\n",
        "real_label=1\n",
        "fake_label=0\n",
        "\n",
        "optimizernetG=optim.Adam(netG.parameters(),lr=lr,betas=(b1,b2))\n",
        "optimizernetD=optim.Adam(netD.parameters(),lr=lr,betas=(b1,b2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24roAR13PACu"
      },
      "source": [
        "#学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AuvpS6f6Hjw"
      },
      "source": [
        "##本番"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cChhVcP3r7M"
      },
      "source": [
        "Generator_losses=[]\n",
        "Discriminator_losses = []\n",
        "Sum_losses = []\n",
        "kld_losses=[]\n",
        "vgg_losses=[]\n",
        "feat_losses=[]\n",
        "L1_losses=[]\n",
        "judge1=[]\n",
        "judge2=[]\n",
        "judge3=[]\n",
        "epoch=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYmt1eByxvEp"
      },
      "source": [
        "i=0\n",
        "netG.train()\n",
        "t1=time.time()\n",
        "for epoch in range(100):\n",
        "   iter_tops = iter(tops_dataloader)\n",
        "   iter_pants=iter(pants_dataloader)\n",
        "   iter_skirt = iter(skirt_dataloader)\n",
        "   iter_person=iter(person_dataloader)\n",
        "\n",
        "   iter_tops_mask = iter(tops_mask_dataloader)\n",
        "   iter_pants_mask=iter(pants_mask_dataloader)\n",
        "   iter_skirt_mask= iter(skirt_mask_dataloader)\n",
        "\n",
        "\n",
        "   t1=time.time()\n",
        "   for tops_data in tops_dataloader:\n",
        "        #0.バッチデータの取得     \n",
        "        tops_real_batch=next(iter_tops)\n",
        "        pants_real_batch=next(iter_pants)\n",
        "        skirt_real_batch=next(iter_skirt)\n",
        "        person_real_batch=next(iter_person)\n",
        "\n",
        "        tops_mask_real_batch=next(iter_tops_mask)\n",
        "        pants_mask_real_batch=next(iter_pants_mask)\n",
        "        skirt_mask_real_batch=next(iter_skirt_mask)\n",
        "       \n",
        "        tops=tops_real_batch[0].to(device)              #[][][][]\n",
        "        pants=pants_real_batch[0].to(device)      #[][][][]\n",
        "        skirt=skirt_real_batch[0].to(device)  \n",
        "        person=person_real_batch[0].to(device)\n",
        "\n",
        "        tops_mask=tops_mask_real_batch[0].to(device)              #[][][][]\n",
        "        pants_mask=pants_mask_real_batch[0].to(device)      #[][][][]\n",
        "        skirt_mask=skirt_mask_real_batch[0].to(device)  \n",
        "\n",
        "\n",
        "        b_size = tops.size(0)#バッチサイズを計算\n",
        "        #print(b_size)\n",
        "        \n",
        "        \n",
        "        #データの連結\n",
        "        input=torch.cat([tops,pants,skirt],dim=1)\n",
        "        seg=torch.cat([tops_mask,pants_mask,skirt_mask],dim=1)\n",
        "        \n",
        "        for j in range(1):\n",
        "          #fakeを生成\n",
        "          \n",
        "          fake,mu,logvar,_=netG(input,seg,_)\n",
        "          #break\n",
        "          \n",
        "          #fake_image=overlay(person,fake,tops_mask,pants_mask,skirt_mask)\n",
        "          \n",
        "\n",
        "          #Discriminator\n",
        "          netD.zero_grad()\n",
        "          item=tops+pants+skirt\n",
        "          \n",
        "          pre_t,featmap_t=netD.Discriminator(item,seg)#正解データ\n",
        "          judge1.append(pre_t.mean())\n",
        "          label = torch.full(pre_t.size(), fill_value=real_label,dtype=torch.float32,device=device)#正解ラベルを設定\n",
        "          D_loss_t = Ladv(pre_t,label)\n",
        "          D_loss_t.backward()\n",
        "\n",
        "          pre_f,featmap_f=netD.Discriminator(fake.detach(),seg)#偽物データ\n",
        "          judge2.append(pre_f.mean())\n",
        "          label.fill_(fake_label)#偽物ラベルを設定\n",
        "          D_loss_f= Ladv(pre_f,label)\n",
        "          D_loss_f.backward()\n",
        "          D_loss=D_loss_t+D_loss_f\n",
        "          optimizernetD.step()\n",
        "          #print(2)\n",
        "\n",
        "          \n",
        "          #Generator\n",
        "          if i%5==0:\n",
        "            netG.zero_grad()\n",
        "            label.fill_(real_label)#正解ラベルを設定\n",
        "            pre_Gf,featmap_f=netD.Discriminator(fake,seg)#偽物データ\n",
        "\n",
        "            ##各種損失\n",
        "            G_loss_f = Ladv(pre_Gf,label)\n",
        "            pre_t,featmap_t=netD.Discriminator(item,seg)#正解データ\n",
        "            kld_loss=KLDloss(mu,logvar)\n",
        "\n",
        "            L1_loss=L1(fake,item)*10\n",
        "            vgg_loss=Lper(item,fake)\n",
        "\n",
        "            kld_losses.append(kld_loss)\n",
        "            vgg_losses.append(vgg_loss)\n",
        "            L1_losses.append(L1_loss)\n",
        "\n",
        "            G_loss=G_loss_f+kld_loss+L1_loss+vgg_loss\n",
        "            #G_loss=L1_loss\n",
        "            G_loss.backward()\n",
        "            optimizernetG.step()\n",
        "          judge3.append(pre_Gf.mean())\n",
        "          #print(\"======================\")\n",
        "\n",
        "\n",
        "          Sum_losses.append(G_loss.detach())\n",
        "          Generator_losses.append(G_loss_f.detach())\n",
        "          Discriminator_losses.append(D_loss.detach())\n",
        "        \n",
        "    \n",
        "        #print(G_loss_f)\n",
        "        #print(D_loss/2)\n",
        "        \n",
        "          if i%10==0:\n",
        "            print(f\"iter{i}\")\n",
        "          i+=1\n",
        "        #break\n",
        "   #break\n",
        "t2=time.time()       \n",
        "   \n",
        "          \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzIDfv1ibZQp"
      },
      "source": [
        "print(t2-t1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE2AQv5tPE12"
      },
      "source": [
        "#画像表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au0sbJ4aLXLJ"
      },
      "source": [
        "plt.figure(figsize=(30,30))\n",
        "plt.imshow(np.transpose(vutils.make_grid((fake).detach().to(device)[:10], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "#vutils.save_image(fake[0],\"4.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw3dsIlcVX5Z"
      },
      "source": [
        "plt.figure(figsize=(30,30))\n",
        "plt.imshow(np.transpose(vutils.make_grid(item.detach().to(device)[:10], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "#vutils.save_image(item[0],\"1.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdJ6hPmXsRPJ"
      },
      "source": [
        "#テスト\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdsOKU9Jai0b"
      },
      "source": [
        "##エンコードなし\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBo08dfksUvr"
      },
      "source": [
        "%cd drive/My\\ Drive\n",
        "#dataroot1=\"smis_left-shoes\"\n",
        "#dataroot2=\"smis_left-shoes_mask\"\n",
        "dataroot3=\"test_smis_pants\"\n",
        "dataroot4=\"test_smis_pants_mask\"\n",
        "#dataroot5=\"smis_right-shoes\"\n",
        "#dataroot6=\"smis_right-shoes_mask\"\n",
        "dataroot7=\"test_smis_skirt\"\n",
        "dataroot8=\"test_smis_skirt_mask\"\n",
        "dataroot9=\"test_smis_tops\"\n",
        "dataroot10=\"test_smis_tops_mask\"\n",
        "dataroot11=\"good_persons_s\"\n",
        "num_thread=0\n",
        "batch_size=10\n",
        "num_epoch=15\n",
        "img_size=(128,96)\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "ngpu=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6VhYfZWsqTz"
      },
      "source": [
        "test_pants_dataset=dset.ImageFolder(root=dataroot3,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_pants_mask_dataset=dset.ImageFolder(root=dataroot4,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_skirt_dataset=dset.ImageFolder(root=dataroot7,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_skirt_mask_dataset=dset.ImageFolder(root=dataroot8,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_tops_dataset=dset.ImageFolder(root=dataroot9,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_tops_mask_dataset=dset.ImageFolder(root=dataroot10,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_person_dataset=dset.ImageFolder(root=dataroot11,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "test_pants_dataloader=torch.utils.data.DataLoader(test_pants_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)    \n",
        "test_pants_mask_dataloader=torch.utils.data.DataLoader(test_pants_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_dataloader=torch.utils.data.DataLoader(test_skirt_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_mask_dataloader=torch.utils.data.DataLoader(test_skirt_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_dataloader=torch.utils.data.DataLoader(test_tops_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_mask_dataloader=torch.utils.data.DataLoader(test_tops_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_person_dataloader=torch.utils.data.DataLoader(test_person_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "\n",
        "device=torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZkMCdTFtQZ_"
      },
      "source": [
        "images=[]\n",
        "i=0\n",
        "netG.eval()\n",
        "for epoch in range(1):\n",
        "   iter_tops = iter(test_tops_dataloader)\n",
        "   iter_pants=iter(test_pants_dataloader)\n",
        "   iter_skirt = iter(test_skirt_dataloader)\n",
        "   #iter_leftshoes=iter(leftshoes_dataloader)\n",
        "   #iter_rightshoes=iter(rightshoes_dataloader)\n",
        "   iter_person=iter(test_person_dataloader)\n",
        "\n",
        "   iter_tops_mask = iter(test_tops_mask_dataloader)\n",
        "   iter_pants_mask=iter(test_pants_mask_dataloader)\n",
        "   iter_skirt_mask= iter(test_skirt_mask_dataloader)\n",
        "   #iter_leftshoes_mask=iter(leftshoes_mask_dataloader)\n",
        "   #iter_rightshoes_mask=iter(rightshoes_mask_dataloader)\n",
        "\n",
        "   t1=time.time()\n",
        "   for tops_data in test_tops_dataloader:\n",
        "        #0.バッチデータの取得     \n",
        "        tops_real_batch=next(iter_tops)\n",
        "        pants_real_batch=next(iter_pants)\n",
        "        skirt_real_batch=next(iter_skirt)\n",
        "        #leftshoes_real_batch=next(iter_leftshoes)\n",
        "        #rightshoes_real_batch=next(iter_rightshoes)\n",
        "        person_real_batch=next(iter_person)\n",
        "\n",
        "        tops_mask_real_batch=next(iter_tops_mask)\n",
        "        pants_mask_real_batch=next(iter_pants_mask)\n",
        "        skirt_mask_real_batch=next(iter_skirt_mask)\n",
        "        #leftshoes_mask_real_batch=next(iter_leftshoes_mask)\n",
        "        #rightshoes_mask_real_batch=next(iter_rightshoes_mask)\n",
        "       \n",
        "        tops=tops_real_batch[0].to(device)              #[][][][]\n",
        "        pants=pants_real_batch[0].to(device)      #[][][][]\n",
        "        skirt=skirt_real_batch[0].to(device)  \n",
        "        #leftshoes=leftshoes_real_batch[0].to(device)            #[][][][]\n",
        "        #rightshoes=rightshoes_real_batch[0].to(device) #[][][][]\n",
        "        person=person_real_batch[0].to(device)\n",
        "\n",
        "        tops_mask=tops_mask_real_batch[0].to(device)              #[][][][]\n",
        "        pants_mask=pants_mask_real_batch[0].to(device)      #[][][][]\n",
        "        skirt_mask=skirt_mask_real_batch[0].to(device)  \n",
        "        #leftshoes_mask=leftshoes_mask_real_batch[0].to(device)            #[][][][]\n",
        "        #rightshoes_mask=rightshoes_mask_real_batch[0].to(device) #[][][][]\n",
        "\n",
        "        b_size = tops.size(0)#バッチサイズを計算\n",
        "        #print(b_size)\n",
        "        \n",
        "        \n",
        "        #データの連結\n",
        "        input=torch.cat([tops,pants,skirt],dim=1)\n",
        "        seg=torch.cat([tops_mask,pants_mask,skirt_mask],dim=1)\n",
        "        \n",
        "        #fakeを生成\n",
        "        fake,z=netG(input,seg,_,test=True)\n",
        "        fake_image=overlay(person,fake,tops_mask,pants_mask,skirt_mask)\n",
        "        vutils.save_image(fake_image[1],f\"result/1_{epoch}.jpg\")\n",
        "        vutils.save_image(fake_image[5],f\"result/5_{epoch}.jpg\")\n",
        "        vutils.save_image(fake_image[6],f\"result/6_{epoch}.jpg\")\n",
        "        vutils.save_image(fake_image[7],f\"result/7_{epoch}.jpg\")\n",
        "        vutils.save_image(fake_image[8],f\"result/8_{epoch}.jpg\")\n",
        "        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfUviL4QIza0"
      },
      "source": [
        "images=[]\n",
        "for i in range(10):\n",
        "  images.append(imageio.imread(f\"result/1_{i}.jpg\"))\n",
        "imageio.mimsave(\"gifs/1.gif\",images)\n",
        "\n",
        "images=[]\n",
        "for i in range(10):\n",
        "  images.append(imageio.imread(f\"result/5_{i}.jpg\"))\n",
        "imageio.mimsave(\"gifs/5.gif\",images)\n",
        "\n",
        "images=[]\n",
        "for i in range(10):\n",
        "  images.append(imageio.imread(f\"result/6_{i}.jpg\"))\n",
        "imageio.mimsave(\"gifs/6.gif\",images)\n",
        "\n",
        "images=[]\n",
        "for i in range(10):\n",
        "  images.append(imageio.imread(f\"result/7_{i}.jpg\"))\n",
        "imageio.mimsave(\"gifs/7.gif\",images)\n",
        "\n",
        "images=[]\n",
        "for i in range(10):\n",
        "  images.append(imageio.imread(f\"result/8_{i}.jpg\"))\n",
        "imageio.mimsave(\"gifs/8.gif\",images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G0BG-n4z07k"
      },
      "source": [
        "plt.figure(figsize=(30,30))\n",
        "plt.imshow(np.transpose(vutils.make_grid(fake_image.detach().to(device)[:10], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLiroFvNarAd"
      },
      "source": [
        "##エンコードあり\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7_iyfm9awTf"
      },
      "source": [
        "%cd drive/My\\ Drive\n",
        "\n",
        "dataroot3=\"yellow_pants\"\n",
        "dataroot4=\"test_smis_pants_mask\"\n",
        "dataroot7=\"yellow_skirt\"\n",
        "dataroot8=\"test_smis_skirt_mask\"\n",
        "dataroot9=\"yellow_tops\"\n",
        "dataroot10=\"test_smis_tops_mask\"\n",
        "dataroot11=\"good_persons_s\"\n",
        "num_thread=0\n",
        "batch_size=11\n",
        "num_epoch=15\n",
        "img_size=(128,96)\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "ngpu=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTezIBH-bOtv"
      },
      "source": [
        "test_pants_dataset=dset.ImageFolder(root=dataroot3,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_pants_mask_dataset=dset.ImageFolder(root=dataroot4,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_skirt_dataset=dset.ImageFolder(root=dataroot7,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_skirt_mask_dataset=dset.ImageFolder(root=dataroot8,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_tops_dataset=dset.ImageFolder(root=dataroot9,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_tops_mask_dataset=dset.ImageFolder(root=dataroot10,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_person_dataset=dset.ImageFolder(root=dataroot11,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "test_pants_dataloader=torch.utils.data.DataLoader(test_pants_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)    \n",
        "test_pants_mask_dataloader=torch.utils.data.DataLoader(test_pants_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_dataloader=torch.utils.data.DataLoader(test_skirt_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_mask_dataloader=torch.utils.data.DataLoader(test_skirt_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_dataloader=torch.utils.data.DataLoader(test_tops_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_mask_dataloader=torch.utils.data.DataLoader(test_tops_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_person_dataloader=torch.utils.data.DataLoader(test_person_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "\n",
        "device=torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbcq-Ki7bQTe"
      },
      "source": [
        "netG.eval()\n",
        "for epoch in range(1):\n",
        "   iter_tops = iter(test_tops_dataloader)\n",
        "   iter_pants=iter(test_pants_dataloader)\n",
        "   iter_skirt = iter(test_skirt_dataloader)\n",
        "\n",
        "   for tops_data in test_tops_dataloader:\n",
        "        #0.バッチデータの取得     \n",
        "        tops_real_batch=next(iter_tops)\n",
        "        pants_real_batch=next(iter_pants)\n",
        "        skirt_real_batch=next(iter_skirt)\n",
        "       \n",
        "        tops=tops_real_batch[0].to(device)              #[][][][]\n",
        "        pants=pants_real_batch[0].to(device)      #[][][][]\n",
        "        skirt=skirt_real_batch[0].to(device)  \n",
        "\n",
        "        b_size = tops.size(0)#バッチサイズを計算\n",
        "          \n",
        "        #データの連結\n",
        "        input=torch.cat([tops,pants,skirt],dim=1)\n",
        "       \n",
        "        #fakeを生成\n",
        "        z=netG(input,_,_,encodeonly=True)\n",
        "        print(z.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ribsUClKe4Ut"
      },
      "source": [
        "images=[]\n",
        "i=0\n",
        "\n",
        "for epoch in range(1):\n",
        "   iter_person=iter(test_person_dataloader)\n",
        "\n",
        "   iter_tops_mask = iter(test_tops_mask_dataloader)\n",
        "   iter_pants_mask=iter(test_pants_mask_dataloader)\n",
        "   iter_skirt_mask= iter(test_skirt_mask_dataloader)\n",
        "  \n",
        "   t1=time.time()\n",
        "   for tops_data in test_tops_mask_dataloader:\n",
        "        #0.バッチデータの取得     \n",
        "        person_real_batch=next(iter_person)\n",
        "        tops_mask_real_batch=next(iter_tops_mask)\n",
        "        pants_mask_real_batch=next(iter_pants_mask)\n",
        "        skirt_mask_real_batch=next(iter_skirt_mask)\n",
        "\n",
        "        person=person_real_batch[0].to(device)\n",
        "        tops_mask=tops_mask_real_batch[0].to(device)              #[][][][]\n",
        "        pants_mask=pants_mask_real_batch[0].to(device)      #[][][][]\n",
        "        skirt_mask=skirt_mask_real_batch[0].to(device)  \n",
        "        \n",
        "        b_size = tops.size(0)#バッチサイズを計算\n",
        "        #print(b_size)\n",
        "        \n",
        "        \n",
        "        #データの連結\n",
        "        seg=torch.cat([tops_mask,pants_mask,skirt_mask],dim=1)\n",
        "        z2=torch.cat([z,z],dim=0)\n",
        "        z4=torch.cat([z2,z2],dim=0)\n",
        "        z8=torch.cat([z4,z4],dim=0)\n",
        "        z10=torch.cat([z8,z2],dim=0)\n",
        "        z=torch.cat([z10,z],dim=0)\n",
        "        print(z.size())\n",
        "        print(seg.size())\n",
        "\n",
        "\n",
        "        \n",
        "        #fakeを生成\n",
        "        fake=netG(_,seg,z,pre=True)\n",
        "        fake_image=overlay(person,fake,tops_mask,pants_mask,skirt_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWkeATxYggnP"
      },
      "source": [
        "plt.figure(figsize=(30,30))\n",
        "plt.imshow(np.transpose(vutils.make_grid(fake_image.detach().to(device)[:10], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "vutils.save_image(fake_image[2],\"0.png\")\n",
        "#print(fake_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxhGkUhLdRRJ"
      },
      "source": [
        "##モーフィング\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV2NIHk-eJ3w"
      },
      "source": [
        "a=z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAPdGGtCeLXF"
      },
      "source": [
        "b=z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddal0wEBeP4O"
      },
      "source": [
        "images=[]\n",
        "i=0\n",
        "n=20\n",
        "for epoch in range(n):\n",
        "   iter_tops = iter(test_tops_dataloader)\n",
        "   iter_pants=iter(test_pants_dataloader)\n",
        "   iter_skirt = iter(test_skirt_dataloader)\n",
        "   #iter_leftshoes=iter(leftshoes_dataloader)\n",
        "   #iter_rightshoes=iter(rightshoes_dataloader)\n",
        "   iter_person=iter(test_person_dataloader)\n",
        "\n",
        "   iter_tops_mask = iter(test_tops_mask_dataloader)\n",
        "   iter_pants_mask=iter(test_pants_mask_dataloader)\n",
        "   iter_skirt_mask= iter(test_skirt_mask_dataloader)\n",
        "   #iter_leftshoes_mask=iter(leftshoes_mask_dataloader)\n",
        "   #iter_rightshoes_mask=iter(rightshoes_mask_dataloader)\n",
        "\n",
        "   t1=time.time()\n",
        "   for tops_data in test_tops_dataloader:\n",
        "        #0.バッチデータの取得     \n",
        "        tops_real_batch=next(iter_tops)\n",
        "        pants_real_batch=next(iter_pants)\n",
        "        skirt_real_batch=next(iter_skirt)\n",
        "        #leftshoes_real_batch=next(iter_leftshoes)\n",
        "        #rightshoes_real_batch=next(iter_rightshoes)\n",
        "        person_real_batch=next(iter_person)\n",
        "\n",
        "        tops_mask_real_batch=next(iter_tops_mask)\n",
        "        pants_mask_real_batch=next(iter_pants_mask)\n",
        "        skirt_mask_real_batch=next(iter_skirt_mask)\n",
        "        #leftshoes_mask_real_batch=next(iter_leftshoes_mask)\n",
        "        #rightshoes_mask_real_batch=next(iter_rightshoes_mask)\n",
        "       \n",
        "        tops=tops_real_batch[0].to(device)              #[][][][]\n",
        "        pants=pants_real_batch[0].to(device)      #[][][][]\n",
        "        skirt=skirt_real_batch[0].to(device)  \n",
        "        #leftshoes=leftshoes_real_batch[0].to(device)            #[][][][]\n",
        "        #rightshoes=rightshoes_real_batch[0].to(device) #[][][][]\n",
        "        person=person_real_batch[0].to(device)\n",
        "\n",
        "        tops_mask=tops_mask_real_batch[0].to(device)              #[][][][]\n",
        "        pants_mask=pants_mask_real_batch[0].to(device)      #[][][][]\n",
        "        skirt_mask=skirt_mask_real_batch[0].to(device)  \n",
        "        #leftshoes_mask=leftshoes_mask_real_batch[0].to(device)            #[][][][]\n",
        "        #rightshoes_mask=rightshoes_mask_real_batch[0].to(device) #[][][][]\n",
        "\n",
        "        b_size = tops.size(0)#バッチサイズを計算\n",
        "        #print(b_size)\n",
        "        \n",
        "        \n",
        "        #データの連結\n",
        "        input=torch.cat([tops,pants,skirt],dim=1)\n",
        "        seg=torch.cat([tops_mask,pants_mask,skirt_mask],dim=1)\n",
        "        \n",
        "        #fakeを生成\n",
        "        alpha=epoch/n\n",
        "        Z=a*(1-alpha)+b*alpha\n",
        "        fake=netG(input,seg,Z,pre=True)\n",
        "        fake_image=overlay(person,fake,tops_mask,pants_mask,skirt_mask)\n",
        "        images.append(fake_image[1].detach())\n",
        "        vutils.save_image(fake_image[1],f\"result/1_{epoch}.jpg\")\n",
        "        #vutils.save_image(fake_image[5],f\"result/5_{epoch}.jpg\")\n",
        "        #vutils.save_image(fake_image[6],f\"result/6_{epoch}.jpg\")\n",
        "        #vutils.save_image(fake_image[7],f\"result/7_{epoch}.jpg\")\n",
        "        #vutils.save_image(fake_image[8],f\"result/8_{epoch}.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMB1ep61XPil"
      },
      "source": [
        "fig=plt.figure(figsize=(30,30))\n",
        "plt.imshow(np.transpose(vutils.make_grid(images[:20], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "fig.savefig(\"mofing.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brU-kRLaek3D"
      },
      "source": [
        "images=[]\n",
        "for i in range(n):\n",
        "  images.append(imageio.imread(f\"result/1_{i}.jpg\"))\n",
        "imageio.mimsave(\"gifs/1.gif\",images)\n",
        "\n",
        "images=[]\n",
        "for i in range(n):\n",
        "  images.append(imageio.imread(f\"result/5_{i}.jpg\"))\n",
        "imageio.mimsave(\"gifs/5.gif\",images)\n",
        "\n",
        "images=[]\n",
        "for i in range(n):\n",
        "  images.append(imageio.imread(f\"result/6_{i}.jpg\"))\n",
        "imageio.mimsave(\"gifs/6.gif\",images)\n",
        "\n",
        "images=[]\n",
        "for i in range(n):\n",
        "  images.append(imageio.imread(f\"result/7_{i}.jpg\"))\n",
        "imageio.mimsave(\"gifs/7.gif\",images)\n",
        "\n",
        "images=[]\n",
        "for i in range(n):\n",
        "  images.append(imageio.imread(f\"result/8_{i}.jpg\"))\n",
        "imageio.mimsave(\"gifs/8.gif\",images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCDnNYDR5E2z"
      },
      "source": [
        "#損失を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbF5Chwy4-_n"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(Generator_losses,label=\"G\")\n",
        "plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.savefig(\"graph01\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEa-2lgd5CQZ"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"Sum Loss During Training\")\n",
        "plt.plot(Sum_losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.savefig(\"graph02\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbGKA4uwqk18"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"kld Loss During Training\")\n",
        "plt.plot(kld_losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(kld_losses[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX7hJ6ysqlP9"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"L1 Loss During Training\")\n",
        "plt.plot(L1_losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.savefig(\"graph02\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz1mgALnqlic"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"vgg Loss During Training\")\n",
        "plt.plot(vgg_losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.savefig(\"graph03\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXP9S4gqEZBo"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"Unet Loss During Training\")\n",
        "plt.plot(judge1,label=\"Dt\")\n",
        "plt.plot(judge2,label=\"Df\")\n",
        "plt.plot(judge3,label=\"Gf\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C8x9ORbnRML"
      },
      "source": [
        "#退避"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj03-0uTn2VN"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nJ8hcALn4jy"
      },
      "source": [
        "%cd drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgWQN8jqKyhP"
      },
      "source": [
        "def avoid_G():    \n",
        "    PATHUnet='drive/My Drive/models/encoderdecoder(0.00002,0.5,0.999,1:5,batch16,L1,item,pool)_5.pth'\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            #'image':img_list,\n",
        "            'Sum_losses':Sum_losses,\n",
        "            'Generator':Generator_losses,\n",
        "            'Vgg':vgg_losses,\n",
        "            'kld':kld_losses,\n",
        "            'L1':L1_losses,\n",
        "            'judge1':judge1,\n",
        "            'judge2':judge2,\n",
        "            'judge3':judge3,\n",
        "            'model_state_dict': netG.state_dict(),\n",
        "            'optimizer_state_dict': optimizernetG.state_dict(),\n",
        "            'criterion1':Ladv.state_dict(),\n",
        "            'criterion2':L1.state_dict(),\n",
        "            'criterion3':Lper.state_dict()\n",
        "\n",
        "            }, PATHUnet)\n",
        "def avoid_D():\n",
        "    PATHD='drive/My Drive/models/discriminator(0.00002,0.5,0.999,1:5,batch16,L1,item,pool)_5.pth'\n",
        "    torch.save({\n",
        "            'Disciriminator_losses':Discriminator_losses,\n",
        "            'model_state_dict': netD.state_dict(),\n",
        "            'optimizer_state_dict': optimizernetD.state_dict()\n",
        "            }, PATHD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt9clXWZoJkY"
      },
      "source": [
        "avoid_G()\n",
        "avoid_D()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9GqQ0mxIvt3"
      },
      "source": [
        "print(epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teIykXZQoV_x"
      },
      "source": [
        "#ロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoBOTMncoahK"
      },
      "source": [
        "PATHG='drive/My Drive/models/encoderdecoder(0.00002,0.5,0.999,1:5,batch16,L1,item,pool)_5.pth'\n",
        "#Unet = EncoderDecoder(ngpu).to(device)\n",
        "optimizernetG= optim.Adam(netG.parameters(),lr=lr,betas=(b1,b2))\n",
        "Ladv=nn.BCELoss()\n",
        "L1=nn.L1Loss()\n",
        "Lper=Vgg19Loss().to(device)\n",
        "\n",
        "checkpoint = torch.load(PATHG)\n",
        "netG.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizernetG.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "Ladv.load_state_dict(checkpoint['criterion1'])\n",
        "L1.load_state_dict(checkpoint['criterion2'])\n",
        "Lper.load_state_dict(checkpoint['criterion3'])\n",
        "epoch = checkpoint['epoch']\n",
        "#img_list=checkpoint['image']\n",
        "Sum_losses=checkpoint['Sum_losses']\n",
        "Generator_losses=checkpoint['Generator']\n",
        "kld_losses=checkpoint['kld']\n",
        "vgg_losses=checkpoint['Vgg']\n",
        "L1_losses=checkpoint[\"L1\"]\n",
        "judge1=checkpoint['judge1']\n",
        "judge2=checkpoint['judge2']\n",
        "judge3=checkpoint['judge3']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7-YxPjPo6WR"
      },
      "source": [
        "PATHD='drive/My Drive/models/discriminator(0.00002,0.5,0.999,1:5,batch16,L1,item,pool)_5.pth'\n",
        "#Discriminator=Discriminator(ngpu).to(device)\n",
        "optimizernetD=optim.Adam(netD.parameters(),lr=lr,betas=(b1,b2))\n",
        "\n",
        "\n",
        "checkpoint = torch.load(PATHD)\n",
        "netD.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizernetD.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "Discriminator_losses=checkpoint['Disciriminator_losses']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zc5n9Rd-EIk"
      },
      "source": [
        "#実際テスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyWy6e36DK5M"
      },
      "source": [
        "##前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q27hdvH-NUi"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uc225Za-DBb"
      },
      "source": [
        "%cd drive/My\\ Drive/segment_geter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujJq1fzQ-PS-"
      },
      "source": [
        "!pip install ninja"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDv-tqCx-SPP"
      },
      "source": [
        "!python simple_extractor.py --dataset lip --model-restore exp-schp-201908261155-lip.pth --input-dir data/LIP/img --output-dir data/out/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_jum4ce-bfh"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaD9R_Ji-gXu"
      },
      "source": [
        "name=5\n",
        "img1=cv2.imread(f\"data/out/{name}..png\")\n",
        "img2=cv2.imread(f\"data/LIP/img/{name}.jpeg\")\n",
        "if img1.shape[0]>img1.shape[1]:\n",
        "    temp=int(img1.shape[1]/96)\n",
        "    w=temp*96\n",
        "    h=temp*128\n",
        "    if h>img1.shape[0]:\n",
        "      w=w/2\n",
        "      h=h/2\n",
        "\n",
        "    y2=img1.shape[0]-(img1.shape[0]-h)/2\n",
        "    y1=img1.shape[0]-((img1.shape[0]-h)/2)-h\n",
        "    if (y1-round(y1))==0.5:\n",
        "      y1=y1-0.5\n",
        "      y2=y2+0.5\n",
        "\n",
        "    x2=img1.shape[1]-(img1.shape[1]-w)/2\n",
        "    x1=img1.shape[1]-((img1.shape[1]-w)/2)-w\n",
        "    if (x1-round(x1))==0.5:\n",
        "      x1=x1+0.5\n",
        "      x2=x2+0.5\n",
        "    img1=img1[int(y1):int(y2),int(x1):int(x2),:]\n",
        "    img2=img2[int(y1):int(y2),int(x1):int(x2),:]\n",
        "    img1=cv2.resize(img1,(96,128))\n",
        "    img2=cv2.resize(img2,(96,128))\n",
        "\n",
        "elif img1.shape[0]<img1.shape[1]:\n",
        "    temp=int(img1.shape[0]/128)\n",
        "    w=temp*96\n",
        "    h=temp*128\n",
        "    if w>img1.shape[1]:\n",
        "      w=w/2\n",
        "      h=h/2\n",
        "\n",
        "    y2=img1.shape[0]-(img1.shape[0]-h)/2\n",
        "    y1=img1.shape[0]-((img1.shape[0]-h)/2)-h\n",
        "    if (y1-round(y1))==0.5:\n",
        "      y1=y1-0.5\n",
        "      y2=y2+0.5\n",
        "\n",
        "    x2=img1.shape[1]-(img1.shape[1]-w)/2\n",
        "    x1=img1.shape[1]-((img1.shape[1]-w)/2)-w\n",
        "    if (x1-round(x1))==0.5:\n",
        "      x1=x1+0.5\n",
        "      x2=x2+0.5\n",
        "    img1=img1[int(y1):int(y2),int(x1):int(x2),:]\n",
        "    img2=img2[int(y1):int(y2),int(x1):int(x2),:]\n",
        "    img1=cv2.resize(img1,(96,128))\n",
        "    img2=cv2.resize(img2,(96,128))\n",
        "\n",
        "cv2_imshow(img1)\n",
        "print(img2.shape)\n",
        "cv2.imwrite(f\"data/persons/person/{name}.jpg\",img2)\n",
        "\n",
        "\n",
        "\n",
        "img1=img1.transpose(2,0,1)\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "zero=np.zeros((1,img1.shape[1],img1.shape[2]))\n",
        "for i in range(img1.shape[1]):\n",
        "    for j in range(img1.shape[2]):\n",
        "      if img1[0][i][j]==128 and img1[1][i][j]==0 and img1[2][i][j]==128:\n",
        "        zero[0][i][j]=1\n",
        "  \n",
        "mask=zero.transpose(1,2,0)\n",
        "cv2.imwrite(f\"tops_mask/mask/{name}.jpg\",mask*255)\n",
        "\n",
        "zero=np.zeros((1,img1.shape[1],img1.shape[2]))\n",
        "for i in range(img1.shape[1]):\n",
        "    for j in range(img1.shape[2]):\n",
        "      if img1[0][i][j]==0 and img1[1][i][j]==0 and img1[2][i][j]==192:\n",
        "        zero[0][i][j]=1\n",
        "  \n",
        "mask=zero.transpose(1,2,0)\n",
        "cv2.imwrite(f\"pants_mask/mask/{name}.jpg\",mask*255)\n",
        "\n",
        "zero=np.zeros((1,img1.shape[1],img1.shape[2]))\n",
        "for i in range(img1.shape[1]):\n",
        "    for j in range(img1.shape[2]):\n",
        "      if img1[0][i][j]==128 and img1[1][i][j]==0 and img1[2][i][j]==64:\n",
        "        zero[0][i][j]=1\n",
        "  \n",
        "mask=zero.transpose(1,2,0)\n",
        "cv2.imwrite(f\"skirt_mask/mask/{name}.jpg\",mask*255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65O2MQ2kDSf_"
      },
      "source": [
        "##テスト"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZpF0QWEDksJ"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhnApQLvDnU2"
      },
      "source": [
        "%cd drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf5qsMmx-ngi"
      },
      "source": [
        "#dataroot1=\"smis_left-shoes\"\n",
        "#dataroot2=\"smis_left-shoes_mask\"\n",
        "#dataroot3=\"test_smis_pants\"\n",
        "dataroot4=\"segment_geter/pants_mask\"\n",
        "#dataroot5=\"smis_right-shoes\"\n",
        "#dataroot6=\"smis_right-shoes_mask\"\n",
        "#dataroot7=\"test_smis_skirt\"\n",
        "dataroot8=\"segment_geter/skirt_mask\"\n",
        "#dataroot9=\"test_smis_tops\"\n",
        "dataroot10=\"segment_geter/tops_mask\"\n",
        "dataroot11=\"segment_geter/data/persons\"\n",
        "num_thread=0\n",
        "batch_size=10\n",
        "num_epoch=15\n",
        "img_size=(128,96)\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "ngpu=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr77IkGKD-fr"
      },
      "source": [
        "\n",
        "test_pants_mask_dataset=dset.ImageFolder(root=dataroot4,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "\n",
        "test_skirt_mask_dataset=dset.ImageFolder(root=dataroot8,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "\n",
        "test_tops_mask_dataset=dset.ImageFolder(root=dataroot10,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_person_dataset=dset.ImageFolder(root=dataroot11,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "test_pants_dataloader=torch.utils.data.DataLoader(test_pants_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)    \n",
        "test_pants_mask_dataloader=torch.utils.data.DataLoader(test_pants_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_dataloader=torch.utils.data.DataLoader(test_skirt_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_mask_dataloader=torch.utils.data.DataLoader(test_skirt_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_dataloader=torch.utils.data.DataLoader(test_tops_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_mask_dataloader=torch.utils.data.DataLoader(test_tops_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_person_dataloader=torch.utils.data.DataLoader(test_person_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "\n",
        "device=torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKoJELwQFU4J"
      },
      "source": [
        "for epoch in range(1):\n",
        "   \n",
        "   iter_person=iter(test_person_dataloader)\n",
        "\n",
        "   iter_tops_mask = iter(test_tops_mask_dataloader)\n",
        "   iter_pants_mask=iter(test_pants_mask_dataloader)\n",
        "   iter_skirt_mask= iter(test_skirt_mask_dataloader)\n",
        "   #iter_leftshoes_mask=iter(leftshoes_mask_dataloader)\n",
        "   #iter_rightshoes_mask=iter(rightshoes_mask_dataloader)\n",
        "\n",
        "   t1=time.time()\n",
        "   for tops_data in test_tops_dataloader:\n",
        "        #0.バッチデータの取得     \n",
        "        \n",
        "        person_real_batch=next(iter_person)\n",
        "\n",
        "        tops_mask_real_batch=next(iter_tops_mask)\n",
        "        pants_mask_real_batch=next(iter_pants_mask)\n",
        "        skirt_mask_real_batch=next(iter_skirt_mask)\n",
        "        #leftshoes_mask_real_batch=next(iter_leftshoes_mask)\n",
        "        #rightshoes_mask_real_batch=next(iter_rightshoes_mask)\n",
        "       \n",
        "       \n",
        "        person=person_real_batch[0].to(device)\n",
        "\n",
        "        tops_mask=tops_mask_real_batch[0].to(device)              #[][][][]\n",
        "        pants_mask=pants_mask_real_batch[0].to(device)      #[][][][]\n",
        "        skirt_mask=skirt_mask_real_batch[0].to(device)  \n",
        "        #leftshoes_mask=leftshoes_mask_real_batch[0].to(device)            #[][][][]\n",
        "        #rightshoes_mask=rightshoes_mask_real_batch[0].to(device) #[][][][]\n",
        "\n",
        "        b_size = tops_mask.size(0)#バッチサイズを計算\n",
        "        #print(b_size)\n",
        "        \n",
        "        \n",
        "        #データの連結\n",
        "        seg=torch.cat([tops_mask,pants_mask,skirt_mask],dim=1)\n",
        "        \n",
        "        #fakeを生成\n",
        "        fake=netG(_,seg,_,test=True)\n",
        "        fake_image=overlay(person,fake,tops_mask,pants_mask,skirt_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "strvvlezHU1R"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(np.transpose(vutils.make_grid(fake_image.detach().to(device)[:10], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}